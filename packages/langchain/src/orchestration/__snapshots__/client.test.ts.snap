// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`orchestration service client returns successful response when maxRetries equals retry configuration 1`] = `
{
  "id": [
    "langchain_core",
    "messages",
    "AIMessage",
  ],
  "kwargs": {
    "additional_kwargs": {
      "finish_reason": "stop",
      "function_call": undefined,
      "index": 0,
      "module_results": {
        "llm": {
          "choices": [
            {
              "finish_reason": "stop",
              "index": 0,
              "message": {
                "content": "Hello! How can I assist you today?",
                "role": "assistant",
              },
            },
          ],
          "created": 172,
          "id": "llm-id",
          "model": "gpt-4o",
          "object": "chat.completion",
          "usage": {
            "completion_tokens": 9,
            "prompt_tokens": 9,
            "total_tokens": 18,
          },
        },
        "templating": [
          {
            "content": "Hello!",
            "role": "user",
          },
        ],
      },
      "request_id": "request-id",
      "tool_calls": undefined,
    },
    "content": "Hello! How can I assist you today?",
    "invalid_tool_calls": [],
    "response_metadata": {
      "created": 172,
      "finish_reason": "stop",
      "function_call": undefined,
      "id": "orchestration-id",
      "index": 0,
      "model": "gpt-4o",
      "object": "chat.completion",
      "system_fingerprint": undefined,
      "tokenUsage": {
        "completionTokens": 9,
        "promptTokens": 9,
        "totalTokens": 18,
      },
      "tool_calls": undefined,
    },
    "tool_calls": [],
  },
  "lc": 1,
  "type": "constructor",
}
`;

exports[`orchestration service client returns successful response when timeout is bigger than delay 1`] = `
{
  "id": [
    "langchain_core",
    "messages",
    "AIMessage",
  ],
  "kwargs": {
    "additional_kwargs": {
      "finish_reason": "stop",
      "function_call": undefined,
      "index": 0,
      "module_results": {
        "llm": {
          "choices": [
            {
              "finish_reason": "stop",
              "index": 0,
              "message": {
                "content": "Hello! How can I assist you today?",
                "role": "assistant",
              },
            },
          ],
          "created": 172,
          "id": "llm-id",
          "model": "gpt-4o",
          "object": "chat.completion",
          "usage": {
            "completion_tokens": 9,
            "prompt_tokens": 9,
            "total_tokens": 18,
          },
        },
        "templating": [
          {
            "content": "Hello!",
            "role": "user",
          },
        ],
      },
      "request_id": "request-id",
      "tool_calls": undefined,
    },
    "content": "Hello! How can I assist you today?",
    "invalid_tool_calls": [],
    "response_metadata": {
      "created": 172,
      "finish_reason": "stop",
      "function_call": undefined,
      "id": "orchestration-id",
      "index": 0,
      "model": "gpt-4o",
      "object": "chat.completion",
      "system_fingerprint": undefined,
      "tokenUsage": {
        "completionTokens": 9,
        "promptTokens": 9,
        "totalTokens": 18,
      },
      "tool_calls": undefined,
    },
    "tool_calls": [],
  },
  "lc": 1,
  "type": "constructor",
}
`;

exports[`orchestration service client supports streaming responses with tool calls 1`] = `
[
  {
    "args": "{"temperature":20",
    "id": "call_O8w2vPQ7pVJBKD4srms1UeOZ",
    "index": 0,
    "name": "convert_temperature_to_fahrenheit",
    "type": "tool_call_chunk",
  },
]
`;
