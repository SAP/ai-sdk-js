openapi: 3.0.0
info:
  title: Orchestration
  description: Orchestration is an inference service which provides common additional capabilities for business AI scenarios, such as content filtering and data masking. At the core of the service is the LLM module which allows for an easy, harmonized access to the language models of gen AI hub. The service is designed to be modular and extensible, allowing for the addition of new modules in the future. Each module can be configured independently and at runtime, allowing for a high degree of flexibility in the orchestration of AI services.
  version: 0.29.3
x-sap-shortText: Enhance content generation with additional capabilities for business AI scenarios.
servers:
  - url: https://api.ai.{region}.ml.hana.ondemand.com/v2/inference/deployments/{orchestration_deployment_id}
    description: Production endpoint for SAP AI Core
    variables:
      region:
        enum:
          - prod.eu-central-1.aws
          - prodeuonly.eu-central-1.aws
          - prod.us-east-1.aws
          - prod.ap-northeast-1.aws
          - prod.ap-southeast-2.aws
          - prod-eu20.westeurope.azure
          - prod-us21.eastus.azure
          - prod-eu30.europe-west3.gcp
          - prod-us30.us-central1.gcp
        default: prod.eu-central-1
      orchestration_deployment_id:
        description: The deployment ID of the orchestration service. To be obtained from the SAP AI Core service using the deployments endpoint.
        default: x111111
externalDocs:
  description: Documentation for SAP AI Core - Orchestration
  url: https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/orchestration
security:
  - Oauth2: []
tags:
  - name: Orchestrated Completion
    description: Run an orchestrated completion inference request
paths:
  /completion:
    post:
      tags:
        - Orchestration Completion
      operationId: orchestration.v1.endpoints.create
      summary: Orchestrated Completion
      description: Run an orchestrated completion inference request
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompletionPostRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CompletionPostResponse'
        '400':
          $ref: '#/components/responses/BadRequest'
        default:
          $ref: '#/components/responses/CommonError'
components:
  securitySchemes:
    Oauth2:
      type: oauth2
      description: OAuth client credentials (client ID and secret) are required. These can be requested from SAP BTP cloud cockpit.
      flows:
        clientCredentials:
          tokenUrl: https://(subdomain_identity_zone).authentication.(host)/oauth/token
          scopes: {}
  schemas:
    CompletionPostRequest:
      type: object
      required:
        - orchestration_config
      properties:
        orchestration_config:
          $ref: '#/components/schemas/OrchestrationConfig'
        input_params:
          type: object
          example:
            inputContext: optimizing supply chain management
          additionalProperties:
            type: string
        messages_history:
          allOf:
            - $ref: '#/components/schemas/ChatMessages'
          description: History of chat messages. Can be used to provide system and assistant messages to set the context of the conversation. Will be merged with the template message
    ChatMessages:
      type: array
      items:
        $ref: '#/components/schemas/ChatMessage'
    ChatMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          example: user
        content:
          type: string
    ChatDelta:
      type: object
      required:
        - content
      properties:
        role:
          type: string
        content:
          type: string
          default: ''
    CompletionPostResponse:
      type: object
      required:
        - request_id
        - orchestration_result
        - module_results
      properties:
        request_id:
          description: ID of the request
          type: string
          example: d4a67ea1-2bf9-4df7-8105-d48203ccff76
        module_results:
          $ref: '#/components/schemas/ModuleResults'
        orchestration_result:
          $ref: '#/components/schemas/LLMModuleResult'
    CompletionPostResponseStreaming:
      type: object
      required:
        - request_id
      properties:
        request_id:
          description: ID of the request
          type: string
        module_results:
          $ref: '#/components/schemas/ModuleResults'
        orchestration_result:
          $ref: '#/components/schemas/LLMModuleResultStreaming'
    OrchestrationConfig:
      type: object
      required:
        - module_configurations
      properties:
        module_configurations:
          $ref: '#/components/schemas/ModuleConfigs'
        stream:
          type: boolean
          description: If true, the response will be streamed back to the client
          default: false
        stream_options:
          $ref: '#/components/schemas/GlobalStreamOptions'
    ModuleConfigs:
      type: object
      required:
        - llm_module_config
        - templating_module_config
      properties:
        llm_module_config:
          $ref: '#/components/schemas/LLMModuleConfig'
        templating_module_config:
          $ref: '#/components/schemas/TemplatingModuleConfig'
        filtering_module_config:
          $ref: '#/components/schemas/FilteringModuleConfig'
        masking_module_config:
          $ref: '#/components/schemas/MaskingModuleConfig'
    ModuleResults:
      description: Results of each module.
      type: object
      additionalProperties: false
      properties:
        templating:
          $ref: '#/components/schemas/ChatMessages'
        input_masking:
          $ref: '#/components/schemas/GenericModuleResult'
        input_filtering:
          $ref: '#/components/schemas/GenericModuleResult'
        llm:
          $ref: '#/components/schemas/LLMModuleResult'
        output_filtering:
          $ref: '#/components/schemas/GenericModuleResult'
        output_unmasking:
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/LLMChoice'
              - $ref: '#/components/schemas/LLMChoiceStreaming'
    GlobalStreamOptions:
      description: Options for streaming. Will be ignored if stream is false.
      type: object
      additionalProperties: false
      properties:
        chunk_size:
          type: integer
          description: Number of characters per chunk that post-LLM modules operate on.
          default: 100
          minimum: 1
          maximum: 10000
    LLMModuleConfig:
      type: object
      required:
        - model_name
        - model_params
      properties:
        model_name:
          description: Model name as in LLM Access configuration
          example: gpt-4
          type: string
        model_params:
          description: Model parameters
          type: object
          example:
            max_tokens: 300
            temperature: 0.1
            frequency_penalty: 0
            presence_penalty: 0
            n: 2
        model_version:
          description: Version of the model to use
          type: string
          default: latest
    GenericModuleResult:
      type: object
      description: Generic module result
      required:
        - message
      properties:
        message:
          type: string
          description: Some message created from the module
          example: Input to LLM is masked successfully.
        data:
          type: object
          description: Additional data object from the module
    LLMModuleResult:
      description: Output of LLM module. Follows the OpenAI spec.
      oneOf:
        - $ref: '#/components/schemas/LLMModuleResultSynchronous'
        - $ref: '#/components/schemas/LLMModuleResultStreaming'
    LLMModuleResultSynchronous:
      type: object
      description: Output of LLM module. Follows the OpenAI spec.
      required:
        - id
        - object
        - created
        - model
        - choices
        - usage
      properties:
        id:
          type: string
          description: ID of the response
          example: chatcmpl-9rO0aLoPKY7RtqkWi1317bazHEVFr
        object:
          type: string
          description: Object type
          example: chat.completion
        created:
          type: integer
          description: Unix timestamp
          example: 1722510700
        model:
          type: string
          description: Model name
          example: gpt-4
        system_fingerprint:
          type: string
          description: System fingerprint
          example: fp_44709d6fcb
        choices:
          type: array
          description: Choices
          items:
            $ref: '#/components/schemas/LLMChoice'
        usage:
          $ref: '#/components/schemas/TokenUsage'
    LLMModuleResultStreaming:
      type: object
      description: Output of LLM module. Follows the OpenAI spec.
      required:
        - id
        - object
        - created
        - model
        - choices
      properties:
        id:
          type: string
          description: ID of the response
        object:
          type: string
          description: Object type
        created:
          type: integer
          description: Unix timestamp
        model:
          type: string
          description: Model name
        system_fingerprint:
          type: string
          description: System fingerprint
        choices:
          type: array
          description: Choices
          items:
            $ref: '#/components/schemas/LLMChoiceStreaming'
        usage:
          $ref: '#/components/schemas/TokenUsage'
    LLMChoice:
      type: object
      required:
        - index
        - message
        - finish_reason
      properties:
        index:
          type: integer
          description: Index of the choice
          example: 0
        message:
          $ref: '#/components/schemas/ChatMessage'
        logprobs:
          type: object
          description: Log probabilities
          additionalProperties:
            type: array
            items:
              type: number
        finish_reason:
          type: string
          description: Reason the model stopped generating tokens. 'stop' if the model hit a natural stop point or a provided stop sequence, 'length' if the maximum token number was reached, 'content_filter' if content was omitted due to a filter enforced by the LLM model provider or the content filtering module
          example: stop
    LLMChoiceStreaming:
      type: object
      required:
        - index
        - delta
      properties:
        index:
          type: integer
          description: Index of the choice
        delta:
          $ref: '#/components/schemas/ChatDelta'
        logprobs:
          type: object
          description: Log probabilities
          additionalProperties:
            type: array
            items:
              type: number
        finish_reason:
          type: string
          description: Reason for stopping the model
    TokenUsage:
      type: object
      description: Usage of tokens in the response
      required:
        - completion_tokens
        - prompt_tokens
        - total_tokens
      properties:
        completion_tokens:
          type: integer
          description: Number of tokens used in the input
          example: 20
        prompt_tokens:
          type: integer
          description: Number of tokens used in the output
          example: 30
        total_tokens:
          type: integer
          description: Total number of tokens used
          example: 50
    TemplatingModuleConfig:
      oneOf:
        - $ref: '#/components/schemas/Template'
    Template:
      type: object
      required:
        - template
      properties:
        template:
          allOf:
            - $ref: '#/components/schemas/ChatMessages'
          description: A chat message array to be formatted with values from input_params. Both role and content can be templated. If messages_history is provided, the templated messages will be appended.
        defaults:
          description: Optional default values for the template. If a parameter has no default it is required.
          type: object
      example:
        template:
          - role: user
            content: How can the features of AI in SAP BTP specifially {​{?product}}, be applied to {​{?inputContext}}
        defaults:
          inputContext: The default text that will be used in the template if inputContext is not set
    FilteringModuleConfig:
      type: object
      properties:
        input:
          allOf:
            - $ref: '#/components/schemas/InputFilteringConfig'
          description: List of provider type and filters
        output:
          allOf:
            - $ref: '#/components/schemas/OutputFilteringConfig'
          description: List of provider type and filters
      additionalProperties: false
    InputFilteringConfig:
      type: object
      required:
        - filters
      additionalProperties: false
      properties:
        filters:
          description: Configuration for content filtering services that should be used for the given filtering step (input filtering or output filtering).
          type: array
          minItems: 1
          items:
            $ref: '#/components/schemas/FilterConfig'
    OutputFilteringConfig:
      type: object
      required:
        - filters
      additionalProperties: false
      properties:
        filters:
          description: Configuration for content filtering services that should be used for the given filtering step (input filtering or output filtering).
          type: array
          minItems: 1
          items:
            $ref: '#/components/schemas/FilterConfig'
        stream_options:
          $ref: '#/components/schemas/FilteringStreamOptions'
    FilteringStreamOptions:
      description: Stream options for output filtering. Will be ignored if stream is false.
      type: object
      additionalProperties: false
      properties:
        overlap:
          type: integer
          description: Number of characters that should be additionally sent to content filtering services from previous chunks as additional context.
          default: 0
          minimum: 0
          maximum: 10000
    FilterConfig:
      oneOf:
        - $ref: '#/components/schemas/AzureContentSafetyFilterConfig'
    AzureContentSafetyFilterConfig:
      type: object
      required:
        - type
      properties:
        type:
          description: String represents name of the filter provider
          type: string
          enum:
            - azure_content_safety
          example: azure_content_safety
        config:
          $ref: '#/components/schemas/AzureContentSafety'
    AzureContentSafety:
      description: Filter configuration for Azure Content Safety
      type: object
      additionalProperties: false
      properties:
        Hate:
          $ref: '#/components/schemas/AzureThreshold'
        SelfHarm:
          $ref: '#/components/schemas/AzureThreshold'
        Sexual:
          $ref: '#/components/schemas/AzureThreshold'
        Violence:
          $ref: '#/components/schemas/AzureThreshold'
    AzureThreshold:
      type: integer
      description: Threshold for the filter. Setting it to `0` blocks content with low severity, whereas `6` is the most permissive and blocks only the highest severity
      enum:
        - 0
        - 2
        - 4
        - 6
      example: 0
    MaskingModuleConfig:
      type: object
      required:
        - masking_providers
      properties:
        masking_providers:
          type: array
          minItems: 1
          items:
            $ref: '#/components/schemas/MaskingProviderConfig'
          description: List of masking service providers
      additionalProperties: false
    MaskingProviderConfig:
      oneOf:
        - $ref: '#/components/schemas/DPIConfig'
    DPIConfig:
      type: object
      required:
        - type
        - method
        - entities
      properties:
        type:
          description: Type of masking service provider
          type: string
          enum:
            - sap_data_privacy_integration
        method:
          description: Type of masking method to be used
          type: string
          enum:
            - anonymization
            - pseudonymization
        entities:
          description: List of entities to be masked
          type: array
          minItems: 1
          items:
            $ref: '#/components/schemas/DPIEntityConfig'
    DPIEntityConfig:
      type: object
      required:
        - type
      properties:
        type:
          description: Type of entity to be masked
          allOf:
            - $ref: '#/components/schemas/DPIEntities'
    DPIEntities:
      description: Default entities supported by data privacy and integration service
      type: string
      enum:
        - profile-person
        - profile-org
        - profile-university
        - profile-location
        - profile-email
        - profile-phone
        - profile-address
        - profile-sapids-internal
        - profile-sapids-public
        - profile-url
        - profile-username-password
        - profile-nationalid
        - profile-iban
        - profile-ssn
        - profile-credit-card-number
        - profile-passport
        - profile-driverlicense
        - profile-nationality
        - profile-religious-group
        - profile-political-group
        - profile-pronouns-gender
        - profile-gender
        - profile-sexual-orientation
        - profile-trade-union
        - profile-sensitive-data
    ErrorResponse:
      type: object
      required:
        - request_id
        - code
        - message
        - location
      properties:
        request_id:
          type: string
          example: d4a67ea1-2bf9-4df7-8105-d48203ccff76
        code:
          type: integer
          example: 400
        message:
          type: string
          example: Model name must be one of ['gpt-4', ...]
        location:
          type: string
          description: Where the error occurred
          example: LLM Module
        module_results:
          $ref: '#/components/schemas/ModuleResults'
  responses:
    BadRequest:
      description: Bad Request
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ErrorResponse'
    CommonError:
      description: Common Error
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ErrorResponse'
