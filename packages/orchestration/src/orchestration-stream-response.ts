import type {
  AssistantChatMessage,
  ChatMessage,
  ChatMessages,
  CompletionPostResponse,
  LlmChoice,
  MessageToolCalls,
  ModuleResults,
  TokenUsage
} from './client/api/schema/index.js';
import type { OrchestrationStream } from './orchestration-stream.js';

/**
 * Orchestration stream response.
 */
export class OrchestrationStreamResponse<T> {
  public _openStream = true;
  public _data: Partial<CompletionPostResponse> = {};
  private _stream: OrchestrationStream<T> | undefined;

  /**
   * Gets the token usage for the response.
   * @returns The token usage for the response.
   */
  getTokenUsage(): TokenUsage | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    return this._data.final_result?.usage;
  }

  /**
   * Gets the finish reason for a specific choice index.
   * @param choiceIndex - The index of the choice to get the finish reason for.
   * @returns The finish reason for the specified choice index.
   */
  getFinishReason(choiceIndex = 0): string | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    return this.findChoiceByIndex(choiceIndex)?.finish_reason;
  }

  /**
   * Parses the orchestration response and returns the content.
   * If the response was filtered, an error is thrown.
   * @param choiceIndex - The index of the choice to parse.
   * @returns The message content.
   */
  getContent(choiceIndex = 0): string | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    const choice = this.findChoiceByIndex(choiceIndex);
    return choice?.message?.content;
  }

  /**
   * Parses the orchestration response and returns the tool calls generated by the model.
   * @param choiceIndex - The index of the choice to parse.
   * @returns The message tool calls.
   */
  getToolCalls(choiceIndex = 0): MessageToolCalls | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    const choice = this.findChoiceByIndex(choiceIndex);
    return choice?.message?.tool_calls;
  }

  /**
   * Parses the orchestration response and returns the refusal message generated by the model.
   * @param choiceIndex - The index of the choice to parse.
   * @returns The refusal string.
   */
  getRefusal(choiceIndex = 0): string | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    const choice = this.findChoiceByIndex(choiceIndex);
    return choice?.message?.refusal;
  }

  /**
   * Messages that can be used for subsequent prompts as message history.
   * @param choiceIndex - The index of the choice to parse.
   * @returns A list of all messages.
   */
  getAllMessages(choiceIndex = 0): ChatMessages | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    const messages: ChatMessage[] =
      this._data.intermediate_results?.templating ?? [];
    const content = this.findChoiceByIndex(choiceIndex)?.message;
    return content ? [...messages, content] : messages;
  }

  /**
   * Gets the assistant message from the response.
   * @param choiceIndex - The index of the choice to use (default is 0).
   * @returns The assistant message.
   */
  getAssistantMessage(choiceIndex = 0): AssistantChatMessage | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    return this.findChoiceByIndex(choiceIndex)?.message;
  }

  /**
   * Gets the intermediate results from the orchestration response.
   * @returns The intermediate results.
   */
  getIntermediateResults(): ModuleResults | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    return this._data.intermediate_results;
  }

  /**
   * Parses the response and returns the choice by index.
   * @param index - The index of the choice to find.
   * @returns An {@link LLMChoice} object associated with the index.
   */
  findChoiceByIndex(index: number): LlmChoice | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    return this.getChoices().find((c: { index: number }) => c.index === index);
  }

  get stream(): OrchestrationStream<T> {
    if (!this._stream) {
      throw new Error('Response stream is undefined.');
    }
    return this._stream;
  }

  private getChoices() {
    return this._data.final_result?.choices ?? [];
  }

  private isStreamOpen(): boolean {
    if (this._openStream) {
      throw Error(
        'The stream is still open, the requested data is not available yet. Please wait until the stream is closed.'
      );
    }
    return this._openStream;
  }

  /**
   * @internal
   */
  set stream(stream: OrchestrationStream<T>) {
    this._stream = stream;
  }
}
