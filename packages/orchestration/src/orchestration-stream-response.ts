import { createLogger } from '@sap-cloud-sdk/util';
import type {
  AssistantChatMessage,
  ChatMessage,
  ChatMessages,
  CompletionPostResponse,
  MessageToolCalls,
  TokenUsage
} from './client/api/schema/index.js';
import type { OrchestrationStream } from './orchestration-stream.js';

const logger = createLogger({
  package: 'orchestration',
  messageContext: 'orchestration-stream-response'
});

/**
 * Orchestration stream response.
 */
export class OrchestrationStreamResponse<T> {
  public _openStream = true;
  public _data: Partial<CompletionPostResponse> = {};
  private _stream: OrchestrationStream<T> | undefined;

  /**
   * Gets the token usage for the response.
   * @returns The token usage for the response.
   */
  public getTokenUsage(): TokenUsage | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    return this._data.orchestration_result?.usage;
  }

  /**
   * Gets the finish reason for a specific choice index.
   * @param choiceIndex - The index of the choice to get the finish reason for.
   * @returns The finish reason for the specified choice index.
   */
  public getFinishReason(choiceIndex = 0): string | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    return this.findChoiceByIndex(choiceIndex)?.finish_reason;
  }

  /**
   * Parses the orchestration response and returns the content.
   * If the response was filtered, an error is thrown.
   * @param choiceIndex - The index of the choice to parse.
   * @returns The message content.
   */
  public getContent(choiceIndex = 0): string | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    const choice = this.findChoiceByIndex(choiceIndex);
    return choice?.message?.content;
  }

  /**
   * Parses the orchestration response and returns the tool calls generated by the model.
   * @param choiceIndex - The index of the choice to parse.
   * @returns The message tool calls.
   */
  public getToolCalls(choiceIndex = 0): MessageToolCalls | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    const choice = this.findChoiceByIndex(choiceIndex);
    return choice?.message?.tool_calls;
  }

  /**
   * Parses the orchestration response and returns the refusal message generated by the model.
   * @param choiceIndex - The index of the choice to parse.
   * @returns The refusal string.
   */
  public getRefusal(choiceIndex = 0): string | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    const choice = this.findChoiceByIndex(choiceIndex);
    return choice?.message?.refusal;
  }

  /**
   * Messages that can be used for subsequent prompts as message history.
   * @param choiceIndex - The index of the choice to parse.
   * @returns A list of all messages.
   */
  public getAllMessages(choiceIndex = 0): ChatMessages | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    const messages: ChatMessage[] = this._data.module_results?.templating ?? [];
    const content = this.findChoiceByIndex(choiceIndex)?.message;
    return content ? [...messages, content] : messages;
  }

  /**
   * Gets the assistant message from the response.
   * @param choiceIndex - The index of the choice to use (default is 0).
   * @returns The assistant message.
   */

  public getAssistantMessage(
    choiceIndex = 0
  ): AssistantChatMessage | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    return this.findChoiceByIndex(choiceIndex)?.message;
  }

  public getResponse(): CompletionPostResponse | undefined {
    if (this.isStreamOpen()) {
      return;
    }
    return this._data as CompletionPostResponse;
  }

  get stream(): OrchestrationStream<T> {
    if (!this._stream) {
      throw new Error('Response stream is undefined.');
    }
    return this._stream;
  }

  private getChoices() {
    return this._data.orchestration_result?.choices ?? [];
  }

  private findChoiceByIndex(index: number) {
    return this.getChoices().find((c: { index: number }) => c.index === index);
  }

  private isStreamOpen(): boolean {
    if (this._openStream) {
      const stacktrace = new Error().stack;
      logger.warn(
        `The stream is still open, the requested data is not available yet. Please wait until the stream is closed.
        Stacktrace: ${stacktrace}`
      );
    }
    return this._openStream;
  }

  /**
   * @internal
   */
  set stream(stream: OrchestrationStream<T>) {
    this._stream = stream;
  }
}
